{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -U --no-cache-dir gdown --pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.025396825396825397"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "128/5040"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.image import imread\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download data of the imagenet-resnet152 model and the human readable labels for the imagenet dataset\n",
    "\n",
    "if not os.path.exists('../data'):\n",
    "    os.system('gdown 1h7S6N_Rx7gdfO3ZunzErZy6H7620EbZK -O ../data.tar.gz')\n",
    "    os.system('tar -xf ../data.tar.gz -C ../')\n",
    "    os.system('rm ../data.tar.gz')\n",
    "if not os.path.exists('../data/imagenet/human_readable_labels.json'):\n",
    "    !wget -nv -O ../data/imagenet/human_readable_labels.json -L https://raw.githubusercontent.com/anishathalye/imagenet-simple-labels/master/imagenet-simple-labels.json\n",
    "\n",
    "data = np.load('../data/imagenet/imagenet-resnet152.npz') \n",
    "example_paths = os.listdir('../data/imagenet/examples')\n",
    "smx = data['smx'] # Softmax output of the model\n",
    "labels = data['labels'].astype(int) # Real labels of the images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 1000 # Number of calibration points\n",
    "confiable_value = 0.75\n",
    "alpha = 1 - confiable_value # 1-alpha is the desired coverage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyzing, I saw that with alpha until $0.25$ I get a good estimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.array([1] * n + [0] * (smx.shape[0]-n)) > 0\n",
    "np.random.shuffle(idx)\n",
    "cal_smx, val_smx = smx[idx,:], smx[~idx,:]\n",
    "cal_labels, val_labels = labels[idx], labels[~idx]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conformal Predction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1: get conformal scores. n = calib_Y.shape[0]\n",
    "cal_scores = 1-cal_smx[np.arange(n),cal_labels]\n",
    "# 2: get adjusted quantile\n",
    "q_level = np.ceil((n+1)*(1-alpha))/n\n",
    "qhat = np.quantile(cal_scores, q_level, method='higher')\n",
    "prediction_sets = val_smx >= (1-qhat) # 3: form prediction sets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "empirical_coverage = prediction_sets[np.arange(prediction_sets.shape[0]),val_labels].mean()\n",
    "print(f\"The empirical coverage is: {empirical_coverage}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/imagenet/human_readable_labels.json') as f:\n",
    "    label_strings = np.array(json.load(f))\n",
    "\n",
    "example_paths =os.listdir('../data/imagenet/examples')\n",
    "for i in range(10):\n",
    "    rand_path = np.random.choice(example_paths)\n",
    "    img = imread('../data/imagenet/examples/' + rand_path )\n",
    "    img_index = int(rand_path.split('.')[0])\n",
    "    prediction_set = smx[img_index] > 1-qhat\n",
    "    plt.figure()\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    print(f\"The prediction set is: {list(label_strings[prediction_set])}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import beta, betabinom\n",
    "from scipy.optimize import brentq\n",
    "import itertools\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ns = [100,1000,10000]\n",
    "alpha = 0.1\n",
    "\n",
    "sns.set_palette('pastel')\n",
    "plt.figure()\n",
    "ax = plt.gca()\n",
    "\n",
    "for i in range(len(ns)):\n",
    "  n = ns[i]\n",
    "  l = np.floor((n+1)*alpha)\n",
    "  a = n + 1 - l\n",
    "  b = l\n",
    "  x = np.linspace(0.825,0.975,1000)\n",
    "  rv = beta(a, b)\n",
    "  ax.plot(x, rv.pdf(x), lw=3, label=f'n={n}')\n",
    "ax.vlines(1-alpha,ymin=0,ymax=150,color='#888888',linestyles='dashed',label=r'$1-\\alpha$')\n",
    "sns.despine(top=True,right=True)\n",
    "plt.yticks([])\n",
    "plt.legend()\n",
    "plt.title('Distribution of coverage (infinite validation set)')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.1\n",
    "epsilons = [0.1,0.05,0.01,0.005,0.001]\n",
    "for epsilon in epsilons:\n",
    "  def _condition(n):\n",
    "    l = np.floor((n+1)*alpha)\n",
    "    a = n + 1 - l\n",
    "    b = l\n",
    "    if (beta.ppf(0.05, a, b) < 1-alpha-epsilon) or (beta.ppf(0.95, a, b) > 1-alpha+epsilon):\n",
    "      return -1\n",
    "    else:\n",
    "      return 1\n",
    "\n",
    "  print(int(np.ceil(brentq(_condition,np.ceil(1/alpha),100000000000))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.image import imread\n",
    "from scipy.optimize import brentq\n",
    "!pip install -U --no-cache-dir gdown --pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load cached data\n",
    "if not os.path.exists('../data'):\n",
    "    os.system('gdown 1h7S6N_Rx7gdfO3ZunzErZy6H7620EbZK -O ../data.tar.gz')\n",
    "    os.system('tar -xf ../data.tar.gz -C ../')\n",
    "    os.system('rm ../data.tar.gz')\n",
    "    \n",
    "data = np.load('../data/coco/coco-tresnetxl.npz')\n",
    "example_paths = os.listdir('../data/coco/examples')\n",
    "\n",
    "sgmd = data['sgmd'] # sigmoid scores\n",
    "labels = data['labels']\n",
    "example_indexes = data['example_indexes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Problem setup\n",
    "n=4952  # number of calibration points\n",
    "alpha = 0.05 # 1-alpha is the desired false negative rate\n",
    "\n",
    "def false_negative_rate(prediction_set, gt_labels):\n",
    "    return 1-((prediction_set * gt_labels).sum(axis=1)/gt_labels.sum(axis=1)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the softmax scores into calibration and validation sets (save the shuffling)\n",
    "idx = np.array([1] * n + [0] * (sgmd.shape[0]-n)) > 0\n",
    "np.random.shuffle(idx)\n",
    "cal_sgmd, val_sgmd = sgmd[idx,:], sgmd[~idx,:]\n",
    "cal_labels, val_labels = labels[idx], labels[~idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the conformal risk control procedure\n",
    "def lamhat_threshold(lam): return false_negative_rate(cal_sgmd>=lam, cal_labels) - ((n+1)/n*alpha - 1/(n+1))\n",
    "lamhat = brentq(lamhat_threshold, 0, 1)\n",
    "prediction_sets = val_sgmd >= lamhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate empirical FNR\n",
    "print(f\"The empirical FNR is: {false_negative_rate(prediction_sets, val_labels)} and the threshold value is: {lamhat}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show some examples\n",
    "label_strings = np.load('../data/coco/human_readable_labels.npy')\n",
    "\n",
    "example_paths =os.listdir('../data/coco/examples')\n",
    "for i in range(10):\n",
    "    rand_path = np.random.choice(example_paths)\n",
    "    img = imread('../data/coco/examples/' + rand_path )\n",
    "    img_index = int(rand_path.split('.')[0])\n",
    "    prediction_set = sgmd[img_index] > 1-lamhat\n",
    "    plt.figure()\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    print(f\"The prediction set is: {list(label_strings[prediction_set])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.image import imread\n",
    "from scipy.optimize import brentq\n",
    "from skimage.transform import rescale, resize\n",
    "!pip install -U --no-cache-dir gdown --pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load cached data\n",
    "if not os.path.exists('../data'):\n",
    "    os.system('gdown 1h7S6N_Rx7gdfO3ZunzErZy6H7620EbZK -O ../data.tar.gz')\n",
    "    os.system('tar -xf ../data.tar.gz -C ../')\n",
    "    os.system('rm ../data.tar.gz')\n",
    "    \n",
    "data = np.load('../data/polyps/polyps-pranet.npz')\n",
    "example_paths = os.listdir('../data/polyps/examples')\n",
    "\n",
    "sgmd = data['sgmd'] # sigmoid scores\n",
    "gt_masks = data['targets']\n",
    "example_indexes = data['example_indexes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Problem setup\n",
    "n=500 # number of calibration points\n",
    "alpha = 0.1 # 1-alpha is the desired false negative rate\n",
    "\n",
    "def false_negative_rate(pred_masks, true_masks):\n",
    "    return 1-((pred_masks * true_masks).sum(axis=1).sum(axis=1)/true_masks.sum(axis=1).sum(axis=1)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the softmax scores into calibration and validation sets (save the shuffling)\n",
    "idx = np.array([1] * n + [0] * (sgmd.shape[0]-n)) > 0\n",
    "np.random.shuffle(idx)\n",
    "cal_sgmd, val_sgmd = sgmd[idx,:], sgmd[~idx,:]\n",
    "cal_gt_masks, val_gt_masks = gt_masks[idx], gt_masks[~idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the conformal risk control procedure\n",
    "def lamhat_threshold(lam): return false_negative_rate(cal_sgmd>=lam, cal_gt_masks) - ((n+1)/n*alpha - 1/n)\n",
    "lamhat = brentq(lamhat_threshold, 0, 1)\n",
    "predicted_masks = val_sgmd >= lamhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate empirical FNR\n",
    "print(f\"The empirical FNR is: {false_negative_rate(predicted_masks, val_gt_masks)} and the threshold value is: {lamhat}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show some examples\n",
    "for i in range(10):\n",
    "    rand_idx = np.random.choice(example_indexes)\n",
    "    img = imread('../data/polyps/examples/' + str(rand_idx) + '.jpg')\n",
    "    gt_mask = imread('../data/polyps/examples/' + str(rand_idx) + '_gt_mask.jpg')\n",
    "    predicted_mask = resize(sgmd[rand_idx] > lamhat, (img.shape[0],img.shape[1]), anti_aliasing=False)\n",
    "    fig, axs = plt.subplots(1,3,figsize=(8.64,4.76))\n",
    "    axs[0].imshow(img)\n",
    "    axs[0].axis('off')\n",
    "    axs[1].imshow(predicted_mask, cmap='gray')\n",
    "    axs[1].axis('off')\n",
    "    axs[2].imshow(gt_mask, cmap='gray')\n",
    "    axs[2].axis('off')\n",
    "    if i == 0:\n",
    "        axs[0].set_title('input')\n",
    "        axs[1].set_title('predicted mask')\n",
    "        axs[2].set_title('ground truth mask')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Erro: -1.39%\n"
     ]
    }
   ],
   "source": [
    "def calculador_erro(nominal, medido):\n",
    "    numerador = medido - nominal\n",
    "    denominador = nominal\n",
    "    return ((numerador / denominador) * 100)\n",
    "\n",
    "nominal = 10.1\n",
    "medido = 9.96\n",
    "erro = calculador_erro(nominal, medido)\n",
    "print(f\"Erro: {erro:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
